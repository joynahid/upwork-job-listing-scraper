# This compose file is designed to run the API only, connecting to an existing PostgreSQL
# To share PostgreSQL with the main scraper, run: docker-compose up -d postgres
# Then run this API with: docker-compose -f docker-compose.api.yml up -d

services:
  upwork-job-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: upwork-job-api
    ports:
      - "8080:8080"
    environment:
      - API_KEY=${API_KEY:-your-secret-api-key-here}
      - PORT=8080
      # PostgreSQL configuration - connects to shared PostgreSQL
      - POSTGRES_HOST=upwork-postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=upwork_jobs
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      # Optional: Mount logs directory if needed
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "--header=X-API-KEY: ${API_KEY:-your-secret-api-key-here}", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - upwork-job-listing-scraper-network

networks:
  upwork-job-listing-scraper-network:
    external: true
